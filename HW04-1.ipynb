{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data\n",
   "id": "6fb9185c83d56e66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "42a9423ff4477fcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### import some packags",
   "id": "a07a3ca87df3c7b5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-20T09:42:16.783538Z",
     "start_time": "2025-09-20T09:42:12.812431Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T09:42:16.790012Z",
     "start_time": "2025-09-20T09:42:16.784590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义数据集类，继承自PyTorch的Dataset类\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data_dir, segment_len=128):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        Args:\n",
    "            data_dir (str): 数据目录路径，包含metadata.json, mapping.json和特征文件\n",
    "            segment_len (int, optional): 每个样本的mel频谱图长度. 默认为128帧.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.segment_len = segment_len\n",
    "\n",
    "        # 加载说话人名称到ID的映射文件\n",
    "        mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "        mapping = json.load(mapping_path.open())\n",
    "        self.speaker2id = mapping[\"speaker2id\"]  # 获取说话人到ID的映射字典\n",
    "\n",
    "        # 加载训练数据的元数据\n",
    "        metadata_path = Path(data_dir) / \"metadata.json\"\n",
    "        # 元数据结构为: {\"speakers\": {speaker1: [{feature_path: \"...\", ...}, ...], ...}}\n",
    "        metadata = json.load(open(metadata_path))[\"speakers\"]\n",
    "\n",
    "        # 获取总说话人数\n",
    "        self.speaker_num = len(metadata.keys())\n",
    "        \n",
    "        # 初始化数据列表，每个元素为[特征文件路径, 说话人ID]\n",
    "        self.data = []\n",
    "        # 遍历每个说话人的所有语音片段\n",
    "        for speaker in metadata.keys():\n",
    "            for utterances in metadata[speaker]:\n",
    "                # 将特征路径和对应的说话人ID加入数据列表\n",
    "                self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集的总样本数\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取单个样本数据，这是Dataset类的核心方法\n",
    "        Args:\n",
    "            index (int): 样本索引\n",
    "        Returns:\n",
    "            tuple: (mel频谱图, 说话人ID)\n",
    "        \"\"\"\n",
    "        # 获取特征文件路径和说话人ID\n",
    "        feat_path, speaker = self.data[index]\n",
    "        \n",
    "        # 加载预处理的mel频谱图特征\n",
    "        mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "        # 将mel频谱图切割成固定长度的片段\n",
    "        if len(mel) > self.segment_len:\n",
    "            # 随机获取片段的起始点，确保不越界\n",
    "            start = random.randint(0, len(mel) - self.segment_len)\n",
    "            # 截取指定长度的mel片段并转换为FloatTensor\n",
    "            mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
    "        else:\n",
    "            # 如果mel长度不足，直接使用全部内容\n",
    "            mel = torch.FloatTensor(mel)\n",
    "        \n",
    "        # 将说话人ID转换为LongTensor，用于后续的损失计算\n",
    "        speaker = torch.FloatTensor([speaker]).long()\n",
    "        \n",
    "        return mel, speaker\n",
    "\n",
    "    def get_speaker_number(self):\n",
    "        \"\"\"返回数据集中说话人的总数\"\"\"\n",
    "        return self.speaker_num\n",
    "        "
   ],
   "id": "b135111389913198",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    自定义批处理函数，用于处理变长序列的填充\n",
    "    Args:\n",
    "        batch: 一个批次的样本列表，每个样本为 (mel, speaker)\n",
    "    Returns:\n",
    "        tuple: 填充后的mel频谱和说话人标签\n",
    "    \"\"\"\n",
    "    # 将batch中的mel和speaker分别解压缩到两个元组中\n",
    "    # mel: 包含多个不同长度的mel频谱图的列表\n",
    "    # speaker: 包含对应说话人ID的列表\n",
    "    mel, speaker = zip(*batch)\n",
    "    \n",
    "    # 对mel频谱进行填充，使一个batch内的所有序列长度相同\n",
    "    # batch_first=True: 输出的张量形状为 (batch_size, seq_len, features)\n",
    "    # padding_value=-20: 填充值为-20，对应log10(10^-20)，是一个很小的数值（近似于静音帧）\n",
    "    mel = pad_sequence(mel, batch_first=True, padding_value=-20)\n",
    "    # 输出mel形状: (batch_size, max_length, n_mels=40)\n",
    "    \n",
    "    # 将说话人ID列表转换为LongTensor并返回\n",
    "    return mel, torch.FloatTensor(speaker).long()\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "    \"\"\"\n",
    "    生成训练和验证数据加载器\n",
    "    Args:\n",
    "        data_dir (str): 数据目录路径\n",
    "        batch_size (int): 每个批次的样本数量\n",
    "        n_workers (int): 数据加载时使用的子进程数\n",
    "    Returns:\n",
    "        tuple: (训练数据加载器, 验证数据加载器, 说话人总数)\n",
    "    \"\"\"\n",
    "    # 创建自定义数据集实例\n",
    "    dataset = myDataset(data_dir)\n",
    "    # 获取数据集中说话人的总数（用于模型输出层的设计）\n",
    "    speaker_num = dataset.get_speaker_number()\n",
    "    \n",
    "    # 将数据集按9:1的比例分割为训练集和验证集\n",
    "    trainlen = int(0.9 * len(dataset))  # 90% 用于训练\n",
    "    lengths = [trainlen, len(dataset) - trainlen]  # 训练集和验证集的大小\n",
    "    trainset, validset = random_split(dataset, lengths)  # 随机分割数据集\n",
    "\n",
    "    # 创建训练数据加载器\n",
    "    train_loader = DataLoader(\n",
    "        trainset,           # 训练数据集\n",
    "        batch_size=batch_size,  # 批次大小\n",
    "        shuffle=True,       # 每个epoch打乱数据顺序，防止模型记忆顺序\n",
    "        drop_last=True,     # 丢弃最后一个不完整的批次，保证批次大小一致\n",
    "        num_workers=n_workers,  # 使用多进程加载数据，加速数据预处理\n",
    "        pin_memory=True,    # 将数据锁页内存，加速GPU数据传输\n",
    "        collate_fn=collate_batch,  # 使用自定义的批处理函数\n",
    "    )\n",
    "    \n",
    "    # 创建验证数据加载器\n",
    "    valid_loader = DataLoader(\n",
    "        validset,           # 验证数据集\n",
    "        batch_size=batch_size,  # 批次大小\n",
    "        num_workers=n_workers,  # 使用多进程加载数据\n",
    "        drop_last=True,     # 丢弃最后一个不完整的批次\n",
    "        pin_memory=True,    # 将数据锁页内存\n",
    "        collate_fn=collate_batch,  # 使用相同的批处理函数\n",
    "        # 注意：验证集不需要shuffle，以便更好地评估模型性能\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, speaker_num"
   ],
   "id": "6567d868623a617f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model\n",
    "TransformerEncoderLayer（Transformer编码器层）：\n",
    "\n",
    "基于Attention Is All You Need论文中的基础Transformer编码器层\n",
    "\n",
    "参数：\n",
    "\n",
    "d_model：输入特征的预期数量（必需）\n",
    "\n",
    "nhead：多头注意力模型中的头数（必需）\n",
    "\n",
    "dim_feedforward：前馈网络模型的维度（默认=2048）\n",
    "\n",
    "dropout：dropout值（默认=0.1）\n",
    "\n",
    "activation：中间层的激活函数，relu或gelu（默认=relu）\n",
    "\n",
    "TransformerEncoder（Transformer编码器）：\n",
    "\n",
    "Transformer编码器是由N个Transformer编码器层堆叠而成的\n",
    "\n",
    "参数：\n",
    "\n",
    "encoder_layer：TransformerEncoderLayer()类的实例（必需）\n",
    "\n",
    "num_layers：编码器中子编码器层的数量（必需）\n",
    "\n",
    "norm：层归一化组件（可选）"
   ],
   "id": "647074e94a4b1b22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "    super().__init__()\n",
    "    # 将输入特征的维度从40投影到d_model\n",
    "    self.prenet = nn.Linear(40, d_model)\n",
    "    \n",
    "    # TODO:\n",
    "    #   将Transformer改为Conformer\n",
    "    #   https://arxiv.org/abs/2005.08100\n",
    "    self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "      d_model=d_model,        # 模型维度\n",
    "      dim_feedforward=256,    # 前馈网络维度\n",
    "      nhead=2                 # 多头注意力头数\n",
    "    )\n",
    "    # self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "\n",
    "    # 将特征维度从d_model投影到说话人数量\n",
    "    self.pred_layer = nn.Sequential(\n",
    "      nn.Linear(d_model, d_model),  # 线性层\n",
    "      nn.ReLU(),                    # ReLU激活函数\n",
    "      nn.Linear(d_model, n_spks),   # 输出层（说话人分类）\n",
    "    )\n",
    "\n",
    "  def forward(self, mels):\n",
    "    \"\"\"\n",
    "    前向传播函数\n",
    "    参数:\n",
    "      mels: (批次大小, 序列长度, 40) - 梅尔频谱特征\n",
    "    返回:\n",
    "      out: (批次大小, n_spks) - 说话人分类概率\n",
    "    \"\"\"\n",
    "    # out: (批次大小, 序列长度, d_model)\n",
    "    out = self.prenet(mels)  # 特征维度投影\n",
    "    \n",
    "    # out: (序列长度, 批次大小, d_model)\n",
    "    out = out.permute(1, 0, 2)  # 调整维度顺序以适应Transformer输入要求\n",
    "    \n",
    "    # 编码器层期望特征形状为 (序列长度, 批次大小, d_model)\n",
    "    out = self.encoder_layer(out)  # Transformer编码处理\n",
    "    \n",
    "    # out: (批次大小, 序列长度, d_model)\n",
    "    out = out.transpose(0, 1)  # 恢复维度顺序\n",
    "    \n",
    "    # 均值池化：沿序列长度维度取平均\n",
    "    stats = out.mean(dim=1)\n",
    "\n",
    "    # out: (批次大小, n_spks) - 说话人分类结果\n",
    "    out = self.pred_layer(stats)\n",
    "    return out\n"
   ],
   "id": "69e83c955413c6b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 学习率调度策略\n",
    "对于Transformer架构，学习率调度方案的设计与卷积神经网络（CNN）有所不同。\n",
    "\n",
    "现有研究表明，学习率预热机制能有效提升基于Transformer架构模型的训练效果。\n",
    "\n",
    "预热调度方案具体表现为：\n",
    "\n",
    "训练初始阶段将学习率设置为0\n",
    "\n",
    "在预热周期内，学习率从0开始线性增长至预设的初始学习率值"
   ],
   "id": "c1aa8042370a50ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math  # 需要导入math模块\n",
    "\n",
    "#为什么这里有的形参后是：确定实参的数据类型\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer: Optimizer,           # 必须是Optimizer类型\n",
    "    num_warmup_steps: int,          # 必须是整数\n",
    "    num_training_steps: int,        # 必须是整数  \n",
    "    num_cycles: float = 0.5,        # 浮点数，默认值0.5\n",
    "    last_epoch: int = -1,           # 整数，默认值-1\n",
    "):\n",
    "    \"\"\"\n",
    "    创建带有预热期的余弦学习率调度器。\n",
    "    \n",
    "    该调度器首先在预热期内将学习率从0线性增加到优化器中设置的初始学习率，\n",
    "    然后按照余弦函数的值从初始学习率递减到0。\n",
    "\n",
    "    参数:\n",
    "        optimizer (:class:`~torch.optim.Optimizer`):\n",
    "            需要调度学习率的优化器\n",
    "        num_warmup_steps (:obj:`int`):\n",
    "            预热阶段的步数\n",
    "        num_training_steps (:obj:`int`):\n",
    "            总训练步数\n",
    "        num_cycles (:obj:`float`, `可选`, 默认为 0.5):\n",
    "            余弦调度中的周期数（默认值0.5表示遵循半个余弦波从最大值下降到0）\n",
    "        last_epoch (:obj:`int`, `可选`, 默认为 -1):\n",
    "            恢复训练时上一个epoch的索引\n",
    "\n",
    "    返回:\n",
    "        :obj:`torch.optim.lr_scheduler.LambdaLR`: 带有相应调度规则的学习率调度器\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        # 预热阶段\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # 衰减阶段\n",
    "        progress = float(current_step - num_warmup_steps) / float(\n",
    "            max(1, num_training_steps - num_warmup_steps)\n",
    "        )\n",
    "        return max(\n",
    "            0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "        )\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ],
   "id": "955ef431946557d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
