{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 下载数据",
   "id": "a72ba65bf2f25b3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## https://drive.google.com/file/d/1zHjG3F8msz9LBPhp_N5kp_O6G9F2Y5w9/view?usp=drive_link",
   "id": "529fbf5684c0be88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !gdown --id '1zHjG3F8msz9LBPhp_N5kp_O6G9F2Y5w9' --output Dataset.zip\n",
    "# !unzip Dataset.zip"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 导入包",
   "id": "fc641a49723b68c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:18.291305Z",
     "start_time": "2025-10-20T06:15:15.930374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime"
   ],
   "id": "5033a17ff649028a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# dataset",
   "id": "1e0443f045d55a2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:18.298670Z",
     "start_time": "2025-10-20T06:15:18.291305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class myDataset(Dataset):\n",
    "  def __init__(self, data_dir, segment_len=128):\n",
    "    \"\"\"初始化数据集\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): 数据目录路径\n",
    "        segment_len (int, optional): 每个片段的帧数，默认为128\n",
    "    \"\"\"\n",
    "    self.data_dir = data_dir\n",
    "    self.segment_len = segment_len\n",
    "\n",
    "    # 加载说话人姓名到ID的映射关系\n",
    "    mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "    mapping = json.load(mapping_path.open())\n",
    "    self.speaker2id = mapping[\"speaker2id\"]\n",
    "\n",
    "    # 加载训练数据的元数据\n",
    "    metadata_path = Path(data_dir) / \"metadata.json\"\n",
    "    metadata = json.load(open(metadata_path))[\"speakers\"]\n",
    "\n",
    "    # 获取说话人总数\n",
    "    self.speaker_num = len(metadata.keys())\n",
    "    self.data = []\n",
    "    \n",
    "    # 遍历所有说话人和他们的语音片段，构建数据列表\n",
    "    # 每个元素包含特征路径和对应的说话人ID\n",
    "    for speaker in metadata.keys():\n",
    "      for utterances in metadata[speaker]:\n",
    "        self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"返回数据集中的样本数量\"\"\"\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"获取指定索引的数据样本\n",
    "    \n",
    "    Args:\n",
    "        index (int): 数据索引\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (mel频谱图, 说话人ID)\n",
    "    \"\"\"\n",
    "    # 获取特征路径和说话人ID\n",
    "    feat_path, speaker = self.data[index]\n",
    "    \n",
    "    # 加载预处理的mel频谱图\n",
    "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "    # 将mel频谱图分割成指定长度的片段\n",
    "    if len(mel) > self.segment_len:\n",
    "      # 随机获取片段的起始点\n",
    "      start = random.randint(0, len(mel) - self.segment_len)\n",
    "      # 截取指定长度的片段\n",
    "      mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
    "    else:\n",
    "      mel = torch.FloatTensor(mel)\n",
    "      \n",
    "    # 将说话人ID转换为long类型，用于后续损失计算\n",
    "    speaker = torch.FloatTensor([speaker]).long()\n",
    "    \n",
    "    return mel, speaker\n",
    "\n",
    "  def get_speaker_number(self):\n",
    "    \"\"\"返回数据集中说话人的总数\"\"\"\n",
    "    return self.speaker_num"
   ],
   "id": "a5a47a7273faaa31",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# dataloader",
   "id": "2267ee73c6b72b85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:18.305298Z",
     "start_time": "2025-10-20T06:15:18.298670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "  \"\"\"处理一个批次的数据\n",
    "  \n",
    "  将同一个批次中的特征进行填充，使它们的长度相同\n",
    "  \n",
    "  Args:\n",
    "      batch: 一个批次的数据，包含mel频谱图和说话人ID\n",
    "  \n",
    "  Returns:\n",
    "      tuple: 填充后的mel频谱图和说话人ID张量\n",
    "  \"\"\"\n",
    "  # 将批次数据解包为mel频谱图和说话人ID\n",
    "  mel, speaker = zip(*batch)\n",
    "  \n",
    "  # 对同一个批次中的mel频谱图进行填充，使它们长度相同\n",
    "  # 使用-20进行填充，对应log10^(-20)，这是一个非常小的值（接近0）\n",
    "  mel = pad_sequence(mel, batch_first=True, padding_value=-20)\n",
    "  \n",
    "  # mel的形状: (批次大小, 序列长度, 40个mel频带)\n",
    "  return mel, torch.FloatTensor(speaker).long()\n",
    "\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "  \"\"\"生成数据加载器\n",
    "  \n",
    "  Args:\n",
    "      data_dir (str): 数据目录路径\n",
    "      batch_size (int): 批次大小\n",
    "      n_workers (int): 数据加载的工作进程数\n",
    "  \n",
    "  Returns:\n",
    "      tuple: 训练数据加载器、验证数据加载器、说话人数量\n",
    "  \"\"\"\n",
    "  # 创建数据集实例\n",
    "  dataset = myDataset(data_dir)\n",
    "  \n",
    "  # 获取数据集中说话人的总数\n",
    "  speaker_num = dataset.get_speaker_number()\n",
    "  \n",
    "  # 将数据集按9:1的比例分割为训练集和验证集\n",
    "  trainlen = int(0.9 * len(dataset))  # 90% 训练集\n",
    "  lengths = [trainlen, len(dataset) - trainlen]  # 训练集和验证集的大小\n",
    "  trainset, validset = random_split(dataset, lengths)  # 随机分割\n",
    "\n",
    "  # 创建训练数据加载器\n",
    "  train_loader = DataLoader(\n",
    "    trainset,                    # 训练数据集\n",
    "    batch_size=batch_size,       # 批次大小\n",
    "    shuffle=True,                # 每个epoch打乱数据\n",
    "    drop_last=True,              # 丢弃最后一个不完整的批次\n",
    "    num_workers=n_workers,       # 数据加载的工作进程数\n",
    "    pin_memory=True,             # 将数据固定在内存中，加速GPU传输\n",
    "    collate_fn=collate_batch,    # 自定义批次处理函数\n",
    "  )\n",
    "  \n",
    "  # 创建验证数据加载器\n",
    "  valid_loader = DataLoader(\n",
    "    validset,                    # 验证数据集\n",
    "    batch_size=batch_size,       # 批次大小\n",
    "    num_workers=n_workers,       # 数据加载的工作进程数\n",
    "    drop_last=True,              # 丢弃最后一个不完整的批次\n",
    "    pin_memory=True,             # 将数据固定在内存中，加速GPU传输\n",
    "    collate_fn=collate_batch,    # 自定义批次处理函数\n",
    "  )\n",
    "\n",
    "  return train_loader, valid_loader, speaker_num"
   ],
   "id": "4c52a417d37de29b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型",
   "id": "1f92df09d4f954e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:18.766385Z",
     "start_time": "2025-10-20T06:15:18.760191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model=80, n_spks=600, dropout=0.1):\n",
    "    \"\"\"初始化分类器模型\n",
    "    \n",
    "    Args:\n",
    "        d_model (int): 模型的特征维度，默认为80\n",
    "        n_spks (int): 说话人数量，默认为600\n",
    "        dropout (float): dropout率，默认为0.1\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    \n",
    "    # 将输入特征的维度从40投影到d_model\n",
    "    # 输入: (batch_size, length, 40) -> 输出: (batch_size, length, d_model)\n",
    "    self.prenet = nn.Linear(40, d_model)\n",
    "    \n",
    "    # TODO: 将Transformer改为Conformer\n",
    "    # 参考论文: https://arxiv.org/abs/2005.08100\n",
    "    # Conformer结合了CNN和Transformer的优点，在语音任务上表现更好\n",
    "    \n",
    "    # 当前使用Transformer编码层\n",
    "    self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "      d_model=d_model,        # 特征维度\n",
    "      dim_feedforward=256,    # 前馈网络的隐藏层维度\n",
    "      nhead=2                 # 注意力头数\n",
    "    )\n",
    "    # 如果需要多层，可以使用TransformerEncoder\n",
    "    # self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "\n",
    "    # 预测层：将d_model维特征映射到说话人数量\n",
    "    self.pred_layer = nn.Sequential(\n",
    "      nn.Linear(d_model, d_model),  # 线性变换\n",
    "      nn.ReLU(),                    # 激活函数\n",
    "      nn.Linear(d_model, n_spks),   # 输出层，输出每个说话人的分数\n",
    "    )\n",
    "\n",
    "  def forward(self, mels):\n",
    "    \"\"\"\n",
    "    前向传播\n",
    "    \n",
    "    Args:\n",
    "      mels: 输入mel频谱图，形状为 (batch_size, length, 40)\n",
    "      \n",
    "    Return:\n",
    "      out: 输出说话人分类结果，形状为 (batch_size, n_spks)\n",
    "    \"\"\"\n",
    "    # 输入投影: (batch_size, length, 40) -> (batch_size, length, d_model)\n",
    "    out = self.prenet(mels)\n",
    "    \n",
    "    # 调整维度以适应Transformer输入要求\n",
    "    # (batch_size, length, d_model) -> (length, batch_size, d_model)\n",
    "    out = out.permute(1, 0, 2)\n",
    "    \n",
    "    # Transformer编码层期望输入形状为 (length, batch_size, d_model)\n",
    "    out = self.encoder_layer(out)\n",
    "    \n",
    "    # 恢复维度: (length, batch_size, d_model) -> (batch_size, length, d_model)\n",
    "    out = out.transpose(0, 1)\n",
    "    \n",
    "    # 均值池化：沿时间维度求平均\n",
    "    # (batch_size, length, d_model) -> (batch_size, d_model)\n",
    "    stats = out.mean(dim=1)\n",
    "\n",
    "    # 通过预测层得到最终分类结果\n",
    "    # (batch_size, d_model) -> (batch_size, n_spks)\n",
    "    out = self.pred_layer(stats)\n",
    "    \n",
    "    return out"
   ],
   "id": "d09a14695cfce82e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 学习率",
   "id": "efe6c8cd9a984539"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:20.175740Z",
     "start_time": "2025-10-20T06:15:20.170249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "  optimizer: Optimizer,\n",
    "  num_warmup_steps: int,\n",
    "  num_training_steps: int,\n",
    "  num_cycles: float = 0.5,\n",
    "  last_epoch: int = -1,\n",
    "):\n",
    "  \"\"\"\n",
    "  创建带有热身阶段的余弦退火学习率调度器\n",
    "  \n",
    "  学习率首先在热身阶段从0线性增加到优化器中设置的初始学习率，\n",
    "  然后按照余弦函数的值从初始学习率下降到0。\n",
    "\n",
    "  Args:\n",
    "    optimizer (:class:`~torch.optim.Optimizer`):\n",
    "      需要调度学习率的优化器\n",
    "    num_warmup_steps (:obj:`int`):\n",
    "      热身阶段的步数\n",
    "    num_training_steps (:obj:`int`):\n",
    "      总的训练步数\n",
    "    num_cycles (:obj:`float`, `optional`, 默认为 0.5):\n",
    "      余弦调度中的波数（默认只是从最大值下降到0，遵循半余弦）\n",
    "    last_epoch (:obj:`int`, `optional`, 默认为 -1):\n",
    "      恢复训练时最后一个epoch的索引\n",
    "\n",
    "  Return:\n",
    "    :obj:`torch.optim.lr_scheduler.LambdaLR`: 带有相应调度策略的学习率调度器\n",
    "  \"\"\"\n",
    "\n",
    "  def lr_lambda(current_step):\n",
    "    \"\"\"计算学习率乘数的lambda函数\n",
    "    \n",
    "    Args:\n",
    "        current_step (int): 当前训练步数\n",
    "    \n",
    "    Returns:\n",
    "        float: 学习率乘数\n",
    "    \"\"\"\n",
    "    # 热身阶段：线性增加学习率\n",
    "    if current_step < num_warmup_steps:\n",
    "      return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    \n",
    "    # 衰减阶段：余弦退火\n",
    "    progress = float(current_step - num_warmup_steps) / float(\n",
    "      max(1, num_training_steps - num_warmup_steps)\n",
    "    )\n",
    "    \n",
    "    # 计算余弦值，确保不会小于0\n",
    "    return max(\n",
    "      0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "    )\n",
    "\n",
    "  # 创建并返回LambdaLR调度器\n",
    "  return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ],
   "id": "5246d8f873aaaa77",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:20.994094Z",
     "start_time": "2025-10-20T06:15:20.984318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_fn(batch, model, criterion, device):\n",
    "  \"\"\"处理一个批次的模型前向传播\n",
    "  \n",
    "  对输入批次数据进行前向传播，计算损失和准确率\n",
    "  \n",
    "  Args:\n",
    "      batch: 一个批次的数据，包含mel频谱图和标签\n",
    "      model: 神经网络模型\n",
    "      criterion: 损失函数\n",
    "      device: 计算设备（CPU或GPU）\n",
    "  \n",
    "  Returns:\n",
    "      tuple: (损失值, 准确率)\n",
    "  \"\"\"\n",
    "\n",
    "  # 解包批次数据，获取mel频谱图和对应的说话人标签\n",
    "  mels, labels = batch\n",
    "  \n",
    "  # 将数据移动到指定设备（GPU或CPU）\n",
    "  mels = mels.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  # 前向传播：通过模型获取预测输出\n",
    "  outs = model(mels)\n",
    "\n",
    "  # 计算损失：比较预测输出和真实标签\n",
    "  loss = criterion(outs, labels)\n",
    "\n",
    "  # 获取预测结果：选择概率最高的说话人ID\n",
    "  preds = outs.argmax(1)\n",
    "  \n",
    "  # 计算准确率：比较预测结果和真实标签，求平均值\n",
    "  accuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "  return loss, accuracy"
   ],
   "id": "258f4954a882ea3b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:22.635880Z",
     "start_time": "2025-10-20T06:15:22.630293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def valid(dataloader, model, criterion, device):\n",
    "  \"\"\"在验证集上进行模型验证\n",
    "\n",
    "  评估模型在验证集上的性能，计算平均损失和准确率\n",
    "\n",
    "  Args:\n",
    "      dataloader: 验证集的数据加载器\n",
    "      model: 神经网络模型\n",
    "      criterion: 损失函数\n",
    "      device: 计算设备（CPU或GPU）\n",
    "\n",
    "  Returns:\n",
    "      float: 验证集的平均准确率\n",
    "  \"\"\"\n",
    "\n",
    "  # 将模型设置为评估模式\n",
    "  # 这会禁用dropout、batch normalization的更新等训练特定操作\n",
    "  model.eval()\n",
    "  \n",
    "  # 初始化累计损失和准确率\n",
    "  running_loss = 0.0\n",
    "  running_accuracy = 0.0\n",
    "  \n",
    "  # 遍历验证集中的所有批次\n",
    "  for i, batch in enumerate(dataloader):\n",
    "    # 禁用梯度计算，节省内存和计算资源\n",
    "    with torch.no_grad():\n",
    "      # 使用model_fn函数计算当前批次的损失和准确率\n",
    "      loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "      \n",
    "      # 累加损失和准确率\n",
    "      running_loss += loss.item()\n",
    "      running_accuracy += accuracy.item()\n",
    "\n",
    "  \n",
    "  # 将模型恢复为训练模式\n",
    "  model.train()\n",
    "\n",
    "  # 返回整个验证集的平均准确率\n",
    "  avg_loss = running_loss / len(dataloader)\n",
    "  avg_accuracy = running_accuracy / len(dataloader)\n",
    "  return avg_loss, avg_accuracy"
   ],
   "id": "5cfda07c6fbfcf5e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T06:15:23.806533Z",
     "start_time": "2025-10-20T06:15:23.800255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BASE_DIR = os.getcwd() \n",
    "data_dir = os.path.join(BASE_DIR, 'Dataset') \n",
    "batch_size = 32\n",
    "n_workers = 8\n",
    "valid_steps = 2000\n",
    "warmup_steps = 1000\n",
    "save_steps = 10000\n",
    "total_steps = 70000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "learning_rates = []\n",
    "best_val_accuracy = 0.0\n",
    "early_stop_counter = 0\n",
    "best_epoch = 0"
   ],
   "id": "516233e13b3ac1bf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建结果目录\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M')\n",
    "log_dir = os.path.join(BASE_DIR, \"results\", time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(f\"结果保存目录: {log_dir}\")"
   ],
   "id": "fc4d2bfc5a3b86bd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-20T06:15:24.310045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    " \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
    "train_iterator = iter(train_loader)\n",
    "print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "model = Classifier(n_spks=speaker_num).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "best_accuracy = -1.0\n",
    "best_state_dict = None\n",
    "\n",
    "\n",
    "for step in range(total_steps):\n",
    "  # Get data\n",
    "  try:\n",
    "    batch = next(train_iterator)\n",
    "  except StopIteration:\n",
    "    train_iterator = iter(train_loader)\n",
    "    batch = next(train_iterator)\n",
    "\n",
    "  train_loss, train_accuracy = model_fn(batch, model, criterion, device)\n",
    "  train_losses.append(train_loss)\n",
    "  train_losses.append(train_loss.item())\n",
    "  batch_loss = train_loss.item()\n",
    "  batch_accuracy = train_accuracy.item()\n",
    "\n",
    "  # Updata model\n",
    "  train_loss.backward()\n",
    "  optimizer.step()\n",
    "  \n",
    "  # 更新学习率并记录\n",
    "  current_lr = scheduler.get_last_lr()[0]\n",
    "  learning_rates.append(current_lr)\n",
    "  scheduler.step()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  \n",
    "  # Do validation\n",
    "  if (step + 1) % valid_steps == 0:\n",
    "\n",
    "    val_loss, val_accuracy  = valid(valid_loader, model, criterion, device)\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    # 早停判断和模型保存\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        # 保存最佳模型\n",
    "        checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_accuracy\": best_val_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_loss\": train_loss\n",
    "        }\n",
    "        path_checkpoint = os.path.join(log_dir, \"checkpoint_best.pkl\")\n",
    "        torch.save(checkpoint, path_checkpoint)\n",
    "        print(f\"✅ 保存最佳模型，验证准确率: {best_val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 保存接近最佳的模型（用于集成）\n",
    "    elif val_accuracy > best_val_accuracy - 2.0:\n",
    "        checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(log_dir, f\"checkpoint_epoch_{epoch}_acc_{val_accuracy:.2f}.pth\"))\n",
    "\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    # 打印训练信息\n",
    "    print(f'Epoch: {epoch:03d}/{MAX_EPOCH}, '\n",
    "          f'训练损失: {train_loss:.4f}, 训练准确率: {train_accuracy:.2f}% , '\n",
    "          f'验证损失: {val_loss:.4f}, 验证准确率: {val_accuracy:.2f}% , '\n",
    "          f'学习率: {current_lr:.6f}, '\n",
    "          f'最佳: {best_val_accuracy:.2f}% @ Epoch {best_epoch}')\n",
    "    print('-' * 80)\n"
   ],
   "id": "235ab66f5269bde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "  def __init__(self, data_dir):\n",
    "    testdata_path = Path(data_dir) / \"testdata.json\"\n",
    "    metadata = json.load(testdata_path.open())\n",
    "    self.data_dir = data_dir\n",
    "    self.data = metadata[\"utterances\"]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    utterance = self.data[index]\n",
    "    feat_path = utterance[\"feature_path\"]\n",
    "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "    return feat_path, mel\n",
    "\n",
    "\n",
    "def inference_collate_batch(batch):\n",
    "  \"\"\"Collate a batch of data.\"\"\"\n",
    "  feat_paths, mels = zip(*batch)\n",
    "\n",
    "  return feat_paths, torch.stack(mels)"
   ],
   "id": "f047d3676df8dc39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def parse_args():\n",
    "  \"\"\"arguments\"\"\"\n",
    "  config = {\n",
    "    \"data_dir\": \"./Dataset\",\n",
    "    \"model_path\": \"./model.ckpt\",\n",
    "    \"output_path\": \"./output.csv\",\n",
    "  }\n",
    "\n",
    "  return config\n",
    "\n",
    "\n",
    "def main(\n",
    "  data_dir,\n",
    "  model_path,\n",
    "  output_path,\n",
    "):\n",
    "  \"\"\"Main function.\"\"\"\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "  mapping_path = Path(data_dir) / \"mapping.json\"\n",
    "  mapping = json.load(mapping_path.open())\n",
    "\n",
    "  dataset = InferenceDataset(data_dir)\n",
    "  dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=inference_collate_batch,\n",
    "  )\n",
    "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "  speaker_num = len(mapping[\"id2speaker\"])\n",
    "  model = Classifier(n_spks=speaker_num).to(device)\n",
    "  model.load_state_dict(torch.load(model_path))\n",
    "  model.eval()\n",
    "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "  results = [[\"Id\", \"Category\"]]\n",
    "  for feat_paths, mels in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "      mels = mels.to(device)\n",
    "      outs = model(mels)\n",
    "      preds = outs.argmax(1).cpu().numpy()\n",
    "      for feat_path, pred in zip(feat_paths, preds):\n",
    "        results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
    "\n",
    "  with open(output_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main(**parse_args())"
   ],
   "id": "7872a7f3e7f98907"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
